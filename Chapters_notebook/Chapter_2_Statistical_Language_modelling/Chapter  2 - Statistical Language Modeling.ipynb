{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computational linguistics is an emerging field that is widely used in analytics, software applications, and contexts where people communicate with machines. Computational linguistics may be defined as a subfield of artificial intelligence. Applications of computational linguistics include machine translation, speech recognition, intelligent Web searching, information retrieval, and intelligent spelling checkers. It is important to understand the preprocessing tasks or the computations that can be performed on natural language text. In the following chapter, we will discuss ways to calculate word frequencies, the Maximum Likelihood Estimation (MLE) model, interpolation on data, and so on. But first, let's go through the various topics that we will cover in this chapter. They are as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•Calculating word frequencies (1-gram, 2-gram, 3-gram)\n",
    "\n",
    "•Developing MLE for a given text\n",
    "\n",
    "•Applying smoothing on the MLE model\n",
    "\n",
    "•Developing a back-off mechanism for MLE\n",
    "\n",
    "•Applying interpolation on data to get a mix and match\n",
    "\n",
    "•Evaluating a language model through perplexity\n",
    "\n",
    "•Applying Metropolis-Hastings in modeling languages\n",
    "\n",
    "•Applying Gibbs sampling in language processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding word frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collocations may be defined as the collection of two or more tokens that tend to exist together. For example, the United States, the United Kingdom, Union of Soviet Socialist Republics, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['De', 'verzekeringsmaatschappijen', 'verhelen', ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import alpino\n",
    "alpino.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'\", 's'),\n",
       " ('arthur', ':'),\n",
       " ('#', '1'),\n",
       " (\"'\", 't'),\n",
       " ('villager', '#'),\n",
       " ('#', '2'),\n",
       " (']', '['),\n",
       " ('1', ':'),\n",
       " ('oh', ','),\n",
       " ('black', 'knight')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.corpus import webtext\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "tokens=[t.lower() for t in webtext.words('grail.txt')]\n",
    "words=BigramCollocationFinder.from_words(tokens)\n",
    "words.nbest(BigramAssocMeasures.likelihood_ratio, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('black', 'knight'),\n",
       " ('clop', 'clop'),\n",
       " ('head', 'knight'),\n",
       " ('mumble', 'mumble'),\n",
       " ('squeak', 'squeak'),\n",
       " ('saw', 'saw'),\n",
       " ('holy', 'grail'),\n",
       " ('run', 'away'),\n",
       " ('french', 'guard'),\n",
       " ('cartoon', 'character'),\n",
       " ('iesu', 'domine'),\n",
       " ('pie', 'iesu'),\n",
       " ('round', 'table'),\n",
       " ('sir', 'robin'),\n",
       " ('clap', 'clap')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import webtext\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "stop = (stopwords.words('english'))\n",
    "stops_filter = lambda w: len(w) < 3 or w in stop\n",
    "tokens=[t.lower() for t in webtext.words('grail.txt')]\n",
    "words=BigramCollocationFinder.from_words(tokens)\n",
    "words.apply_word_filter(stops_filter)\n",
    "words.nbest(BigramAssocMeasures.likelihood_ratio, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 'Never'),\n",
       " ('Hardwork', 'is'),\n",
       " ('Never', 'give'),\n",
       " ('give', 'up'),\n",
       " ('is', 'the'),\n",
       " ('key', 'to'),\n",
       " ('success', '.'),\n",
       " ('the', 'key'),\n",
       " ('to', 'success'),\n",
       " ('up', '!')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1=\"Hardwork is the key to success. Never give up!\"\n",
    "word = nltk.wordpunct_tokenize(text1)\n",
    "finder = BigramCollocationFinder.from_words(word)\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "value = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "sorted(bigram for bigram, score in value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hello', 'how', 'are', 'you') 2\n",
      "('how', 'are', 'you', 'doing') 1\n",
      "('are', 'you', 'doing', '?') 1\n",
      "('you', 'doing', '?', 'I') 1\n",
      "('doing', '?', 'I', 'hope') 1\n",
      "('?', 'I', 'hope', 'you') 1\n",
      "('I', 'hope', 'you', 'find') 1\n",
      "('hope', 'you', 'find', 'the') 1\n",
      "('you', 'find', 'the', 'book') 1\n",
      "('find', 'the', 'book', 'interesting') 1\n",
      "('the', 'book', 'interesting', 'Hello') 1\n",
      "('book', 'interesting', 'Hello', 'how') 1\n",
      "('interesting', 'Hello', 'how', 'are') 1\n"
     ]
    }
   ],
   "source": [
    "text=\"Hello how are you doing ? I hope you find the book interesting Hello how are you\"\n",
    "tokens=nltk.wordpunct_tokenize(text)\n",
    "fourgrams=nltk.collocations.QuadgramCollocationFinder.from_words(tokens)\n",
    "for fourgram, freq in fourgrams.ngram_fd.items():\n",
    "    print(fourgram,freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hello', ',', 'please', 'read', 'the')\n",
      "(',', 'please', 'read', 'the', 'book')\n",
      "('please', 'read', 'the', 'book', 'thoroughly')\n",
      "('read', 'the', 'book', 'thoroughly', '.')\n",
      "('the', 'book', 'thoroughly', '.', 'If')\n",
      "('book', 'thoroughly', '.', 'If', 'you')\n",
      "('thoroughly', '.', 'If', 'you', 'have')\n",
      "('.', 'If', 'you', 'have', 'anyqueries')\n",
      "('If', 'you', 'have', 'anyqueries', ',')\n",
      "('you', 'have', 'anyqueries', ',', 'then')\n",
      "('have', 'anyqueries', ',', 'then', \"don't\")\n",
      "('anyqueries', ',', 'then', \"don't\", 'hesitate')\n",
      "(',', 'then', \"don't\", 'hesitate', 'to')\n",
      "('then', \"don't\", 'hesitate', 'to', 'ask')\n",
      "(\"don't\", 'hesitate', 'to', 'ask', '.')\n",
      "('hesitate', 'to', 'ask', '.', 'There')\n",
      "('to', 'ask', '.', 'There', 'is')\n",
      "('ask', '.', 'There', 'is', 'no')\n",
      "('.', 'There', 'is', 'no', 'shortcut')\n",
      "('There', 'is', 'no', 'shortcut', 'to')\n",
      "('is', 'no', 'shortcut', 'to', 'success.')\n"
     ]
    }
   ],
   "source": [
    "sent=\" Hello , please read the book thoroughly . If you have anyqueries , then don't hesitate to ask . There is no shortcut to success.\"\n",
    "n = 5\n",
    "n_grams=ngrams(sent.split(),n)\n",
    "for grams in n_grams:\n",
    "    print(grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop MLE for a given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "dfhdfh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
