{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parts-of-Speech Tagging – Identifying Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parts-of-speech (POS) tagging is one of the many tasks in NLP. It is defined as the process of assigning a particular parts-of-speech tag to individual words in a sentence. The parts-of-speech tag identifies whether a word is a noun, verb, adjective, and so on. There are numerous applications of parts-of-speech tagging, such as information retrieval, machine translation, NER, language analysis, and so on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This chapter will include the following topics:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "•Creating POS tagged corpora\n",
    "•Selecting a machine learning algorithm\n",
    "•Statistical modeling involving the n-gram approach\n",
    "•Developing a chunker using POS tagged data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing parts-of-speech tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing parts-of-speech tagging\n",
    "Parts-of-speech tagging is the process of assigning a category (for example, noun, verb, adjective, and so on) tag to individual tokens in a sentence. In NLTK, taggers are present in the nltk.tag package and it is inherited by the TaggerIbase class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('pleasant', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " ('today', 'NN')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "text1=nltk.word_tokenize(\"It is a pleasant day today\")\n",
    "nltk.pos_tag(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NNS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('VB.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('bear', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('pain', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('bear', 'NN')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=nltk.word_tokenize(\"I cannot bear the pain of bear\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bear', 'NN')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taggedword=nltk.tag.str2tuple('bear/NN')\n",
    "taggedword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(taggedword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence='''The/DT sacred/VBN Ganga/NNP flows/VBZ in/IN this/DT\n",
    "region/NN ./. This/DT is/VBZ a/DT pilgrimage/NN ./. People/NNP from/IN\n",
    "all/DT over/IN the/DT country/NN visit/NN this/DT place/NN ./. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('sacred', 'VBN'),\n",
       " ('Ganga', 'NNP'),\n",
       " ('flows', 'VBZ'),\n",
       " ('in', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('region', 'NN'),\n",
       " ('.', '.'),\n",
       " ('This', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('pilgrimage', 'NN'),\n",
       " ('.', '.'),\n",
       " ('People', 'NNP'),\n",
       " ('from', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('over', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('country', 'NN'),\n",
       " ('visit', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('place', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tags = [nltk.tag.str2tuple(t) for t in sentence.split()]\n",
    "sentence_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bear/NN'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taggedtok = ('bear', 'NN')\n",
    "from nltk.tag.util import tuple2str\n",
    "tuple2str(taggedtok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "treebank_tagged = treebank.tagged_words(tagset='universal')\n",
    "tag = nltk.FreqDist(tag for (word, tag) in treebank_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'NOUN': 28867, 'VERB': 13564, '.': 11715, 'ADP': 9857, 'DET': 8725, 'X': 6613, 'ADJ': 6397, 'NUM': 3546, 'PRT': 3219, 'ADV': 3171, ...})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOUN',\n",
       " 'DET',\n",
       " 'ADJ',\n",
       " 'ADP',\n",
       " '.',\n",
       " 'VERB',\n",
       " 'NUM',\n",
       " 'PRT',\n",
       " 'CONJ',\n",
       " 'PRON',\n",
       " 'X',\n",
       " 'ADV']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagpairs = nltk.bigrams(treebank_tagged)\n",
    "preceders_noun = [x[1] for (x, y) in tagpairs if y[1] == 'NOUN']\n",
    "freqdist = nltk.FreqDist(preceders_noun)\n",
    "[tag for (tag, _) in freqdist.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beautiful': 'ADJ', 'boy': 'N', 'read': 'V', 'generously': 'ADV'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag={}\n",
    "tag\n",
    "{}\n",
    "tag['beautiful']='ADJ'\n",
    "tag\n",
    "{'beautiful': 'ADJ'}\n",
    "tag['boy']='N'\n",
    "tag['read']='V'\n",
    "tag['generously']='ADV'\n",
    "tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default tagging is a kind of tagging that assigns identical parts-of-speech tags to\n",
    "all the tokens. The subclass of SequentialBackoffTagger is DefaultTagger. The\n",
    "choose_tag() method must be implemented by SequentialBackoffTagger. \n",
    "\n",
    "This method includes the following arguments:\n",
    "\n",
    "• A collection of tokens\n",
    "\n",
    "• The index of the token that should be tagged\n",
    "\n",
    "• The previous tags list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Beautiful', 'NN'), ('morning', 'NN')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import DefaultTagger\n",
    "tag = DefaultTagger('NN')\n",
    "tag.tag(['Beautiful', 'morning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beautiful', 'morning']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import untag\n",
    "untag([('beautiful', 'NN'), ('morning', 'NN')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating POS-tagged corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A corpus may be known as a collection of documents. A corpora is the collection\n",
    "of multiple corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female.txt', 'male.txt']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2943"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names.words('male.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5001"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names.words('female.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en', 'en-basic']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "words.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235886"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words.words('en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words.words('en-basic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import *\n",
    "from nltk.tag import *\n",
    "def pos_tag(tok):\n",
    "    tagger = load(_POS_TAGGER)\n",
    "    return tagger.tag(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_pos_tag(sent):\n",
    "    tagger = load(_POS_TAGGER)\n",
    "    return tagger.batch_tag(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting a machine learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS tagging is also referred to as word category disambiguation or grammatical tagging. POS tagging may be of two types: rule-based or stochastic/probabilistic.\n",
    "E. Brill's tagger is based on the rule-based tagging algorithm.\n",
    "A POS classifier takes a document as input and obtains word features. It trains itself\n",
    "with the help of these word features combined with the already available training\n",
    "labels. This type of classifier is referred to as a second order classifier, and it makes\n",
    "use of the bootstrap classifier in order to generate the tags for words.\n",
    "A backoff classifier is one in which backoff procedure is performed. The output\n",
    "is obtained in such a manner that the trigram POS tagger relies on the bigram POS\n",
    "tagger, which in turn relies on the unigram POS tagger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NLTK, FastBrillTagger is based on unigram. It makes use of a dictionary of\n",
    "words that are already known and the pos tag information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification \n",
    "Classification may be defined as the process of deciding a POS tag for a given input.\n",
    "In supervised classification, a training corpus is used that comprises a word and its\n",
    "correct tag. In unsupervised classification, any pair of words and a correct tag list\n",
    "does not exist:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In supervised classification, during training, a feature extractor accepts the input\n",
    "and labels and generates a set of features. These features set along with the label\n",
    "act as input to machine learning algorithms. During the testing or prediction phase,\n",
    "a feature extractor is used that generates features from unknown inputs, and the\n",
    "output is sent to a classifier model that generates an output in the form of label or\n",
    "pos tag information with the help of machine learning algorithms.\n",
    "The maximum entropy classifier is one in that searches the parameter set in order to\n",
    "maximize the total likelihood of the corpus used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical modeling involving the n-gram approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram means a single word. In a unigram tagger, a single token is used to find the\n",
    "particular parts-of-speech tag.\n",
    "Training of UnigramTagger can be performed by providing it with a list of sentences\n",
    "at the time of initialization.\n",
    "\n",
    "Let's see the following code in NLTK, which performs UnigramTagger training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "training= treebank.tagged_sents()[:7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.collections.LazySubsequence"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3914"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitagger=UnigramTagger(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<UnigramTagger: size=12408>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unitagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.tag.sequential.UnigramTagger"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(unitagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr.',\n",
       " 'Vinken',\n",
       " 'is',\n",
       " 'chairman',\n",
       " 'of',\n",
       " 'Elsevier',\n",
       " 'N.V.',\n",
       " ',',\n",
       " 'the',\n",
       " 'Dutch',\n",
       " 'publishing',\n",
       " 'group',\n",
       " '.']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treebank.sents()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mr.', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('chairman', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('Elsevier', 'NNP'),\n",
       " ('N.V.', 'NNP'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('Dutch', 'JJ'),\n",
       " ('publishing', 'NN'),\n",
       " ('group', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unitagger.tag(treebank.sents()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate UnigramTagger, let's see the following code, which calculates the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9619024159944167"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = treebank.tagged_sents()[2000:]\n",
    "unitagger.evaluate(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitag = UnigramTagger(model={'Vinken': 'NN'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.tag.sequential.UnigramTagger"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(unitag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mr.', None),\n",
       " ('Vinken', 'NN'),\n",
       " ('is', None),\n",
       " ('chairman', None),\n",
       " ('of', None),\n",
       " ('Elsevier', None),\n",
       " ('N.V.', None),\n",
       " (',', None),\n",
       " ('the', None),\n",
       " ('Dutch', None),\n",
       " ('publishing', None),\n",
       " ('group', None),\n",
       " ('.', None)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unitag.tag(treebank.sents()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, in the preceding code, UnigramTagger only tags 'Vinken' with the 'NN'\n",
    "tag and the rest are tagged with the 'None' tag since we have provided the tag for\n",
    "the word 'Vinken' in the context model and no other words are included in the\n",
    "context model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backoff tagging may be defined as a feature of SequentialBackoffTagger. All the\n",
    "taggers are chained together so that if one of the taggers is unable to tag a token, then\n",
    "the token may be passed to the next tagger.\n",
    "\n",
    "Let's see the following code, which uses back-off tagging. Here, DefaultTagger and\n",
    "UnigramTagger are used to tag a token. If any tagger of them is unable to tag a word,\n",
    "then the next tagger may be used to tag it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9619024159944167"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import DefaultTagger\n",
    "testing = treebank.tagged_sents()[2000:]\n",
    "training= treebank.tagged_sents()[:7000]\n",
    "tag1=DefaultTagger('NN')\n",
    "tag2=UnigramTagger(training,backoff=tag1)\n",
    "tag2.evaluate(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subclasses of NgramTagger are UnigramTagger, BigramTagger, and\n",
    "TrigramTagger. BigramTagger makes use of the previous tag as contextual\n",
    "information. TrigramTagger uses the previous two tags as contextual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n"
     ]
    }
   ],
   "source": [
    "training_1= treebank.tagged_sents()[:7000]\n",
    "bigramtagger=BigramTagger(training_1)\n",
    "print(treebank.sents()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(bigramtagger.tag(treebank.sents()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9171131227292321"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_1 = treebank.tagged_sents()[2000:]\n",
    "bigramtagger.evaluate(testing_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NgramTagger can be used to generate a tagger for n greater than three as well. Let's\n",
    "see the following code in NLTK, which develops QuadgramTagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9304554878173943"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadgramtag = NgramTagger(4, training)\n",
    "quadgramtag.evaluate(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2902682841718497"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affixtag = AffixTagger(training)\n",
    "affixtag.evaluate(testing)           # Uses prefix or suffix as the contextual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2094751318841472"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixtag = AffixTagger(training, affix_length=4)     # learns the use of four character prefixes\n",
    "prefixtag.evaluate(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TnT is Trigrams n Tags. TnT is a statistical-based tagger that is based on the\n",
    "second order Markov models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import tnt\n",
    "tnt_tagger=tnt.TnT()\n",
    "tnt_tagger.train(training)\n",
    "tnt_tagger.evaluate(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing a chunker using pos-tagged corpora\n",
    "Chunking is the process used to perform entity detection. It is used for the\n",
    "segmentation and labeling of multiple sequences of tokens in a sentence.\n",
    "To design a chunker, a chunk grammar should be defined. A chunk grammar\n",
    "holds the rules of how chunking should be done.\n",
    "\n",
    "Let's consider the example that performs Noun Phrase Chunking by forming the\n",
    "chunk rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=[(\"A\",\"DT\"),(\"wise\", \"JJ\"), (\"small\", \"JJ\"),(\"girl\", \"NN\"),\n",
    "(\"of\", \"IN\"), (\"village\", \"N\"), (\"became\", \"VBD\"), (\"leader\", \"NN\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'DT'), ('wise', 'JJ'), ('small', 'JJ'), ('girl', 'NN'), ('of', 'IN'), ('village', 'N'), ('became', 'VBD'), ('leader', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP A/DT wise/JJ small/JJ girl/NN of/IN)\n",
      "  village/N\n",
      "  became/VBD\n",
      "  (NP leader/NN))\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN><IN>?<NN>*}\"\n",
    "find = nltk.RegexpParser(grammar)\n",
    "res = find.parse(sent)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S financial/NN year/NN account/NN summary/NN)\n"
     ]
    }
   ],
   "source": [
    "noun1=[(\"financial\",\"NN\"),(\"year\",\"NN\"),(\"account\",\"NN\"),(\"summary\",\"NN\")]\n",
    "gram=\"NP:{<NN>+}\"\n",
    "find = nltk.RegexpParser(gram)\n",
    "print(find.parse(noun1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=find.parse(noun1)\n",
    "x.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunking is the process in which some of the parts of a chunk are eliminated. Either\n",
    "an entire chunk may be used, a part of the chunk may be used from the middle and\n",
    "the remaining parts are eliminated, or a part of chunk may be used either from the\n",
    "beginning of the chunk or from the end of the chunk and the remaining part of the\n",
    "chunk is removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "dfhdfh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
